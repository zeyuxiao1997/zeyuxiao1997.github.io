<!DOCTYPE html>












  


<html class="theme-next mist use-motion" lang="en">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">




  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2">





















<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2">

<link rel="stylesheet" href="/css/main.css?v=7.1.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.1.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/icon-money32.png?v=7.1.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/icon-money16.png?v=7.1.0">


  <link rel="mask-icon" href="/images/logo.svg?v=7.1.0" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '7.1.0',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false,"dimmer":false},
    back2top: true,
    back2top_sidebar: false,
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="pytorch的相关学习记录、困惑、学习笔记等，持续更新。">
<meta name="keywords" content="pytorch">
<meta property="og:type" content="article">
<meta property="og:title" content="pytorch的一些学习记录&#x2F;困惑&#x2F;笔记等(持续更新)">
<meta property="og:url" content="https://zeyuxiao1997.github.io/2019/04/25/pytorch-learn/index.html">
<meta property="og:site_name" content="ZeyuXiao @ USTC">
<meta property="og:description" content="pytorch的相关学习记录、困惑、学习笔记等，持续更新。">
<meta property="og:locale" content="en">
<meta property="og:image" content="https://zeyuxiao1997.github.io/2019/04/25/pytorch-learn/1.png">
<meta property="og:image" content="https://zeyuxiao1997.github.io/2019/04/25/pytorch-learn/2.png">
<meta property="og:updated_time" content="2019-08-06T08:25:59.390Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="pytorch的一些学习记录&#x2F;困惑&#x2F;笔记等(持续更新)">
<meta name="twitter:description" content="pytorch的相关学习记录、困惑、学习笔记等，持续更新。">
<meta name="twitter:image" content="https://zeyuxiao1997.github.io/2019/04/25/pytorch-learn/1.png">



  <link rel="alternate" href="/atom.xml" title="ZeyuXiao @ USTC" type="application/atom+xml">



  
  
  <link rel="canonical" href="https://zeyuxiao1997.github.io/2019/04/25/pytorch-learn/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>pytorch的一些学习记录/困惑/笔记等(持续更新) | ZeyuXiao @ USTC</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">ZeyuXiao @ USTC</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">Paper reading notes, code sharing platforms</p>
      
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    
      
    

    
      
    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>Home</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-about">

    
    
    
      
    

    
      
    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>About</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    
      
    

    
      
    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>Tags<span class="badge">43</span></a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    
      
    

    
      
    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>Categories<span class="badge">11</span></a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    
      
    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>Archives<span class="badge">43</span></a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-resume-&-publications">

    
    
    
      
    

    
      
    

    <a href="/resume/" rel="section"><i class="menu-item-icon fa fa-fw fa-heartbeat"></i> <br>resume & publications</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-links">

    
    
    
      
    

    
      
    

    <a href="/links/" rel="section"><i class="menu-item-icon fa fa-fw fa-sitemap"></i> <br>links</a>

  </li>

      
      
    </ul>
  

  
    

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://zeyuxiao1997.github.io/2019/04/25/pytorch-learn/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Zeyuxiao">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ZeyuXiao @ USTC">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">pytorch的一些学习记录/困惑/笔记等(持续更新)

              
            
          </h1>
        

        <div class="post-meta">
            
                <span class="post-meta-item-icon">
                    <i class="fa fa-thumb-tack"></i>
                </span>
                <font color="red">置顶</font>
                <span class="post-meta-divider">|</span>
                    
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-04-25 16:13:25" itemprop="dateCreated datePublished" datetime="2019-04-25T16:13:25+08:00">2019-04-25</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2019-08-06 16:25:59" itemprop="dateModified" datetime="2019-08-06T16:25:59+08:00">2019-08-06</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Technical-guide/" itemprop="url" rel="index"><span itemprop="name">Technical guide</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          
            <span id="/2019/04/25/pytorch-learn/" class="leancloud_visitors" data-flag-title="pytorch的一些学习记录/困惑/笔记等(持续更新)">
              <span class="post-meta-divider">|</span>
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              
                <span class="post-meta-item-text">Views: </span>
              
                <span class="leancloud-visitors-count"></span>
            </span>
          

          
            <span class="post-meta-divider">|</span>
            <span class="post-meta-item-icon">
            <i class="fa fa-eye"></i>
             Views:  
            <span class="busuanzi-value" id="busuanzi_value_page_pv"></span>
            </span>
          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Symbols count in article: </span>
                
                <span title="Symbols count in article">9.6k</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">12 mins.</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>pytorch的相关学习记录、困惑、学习笔记等，持续更新。<br><a id="more"></a></p>
<h2 id="查看网络参数总量"><a href="#查看网络参数总量" class="headerlink" title="查看网络参数总量"></a>查看网络参数总量</h2><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">netG = Generator(UPSCALE_FACTOR)</span><br><span class="line"><span class="comment"># here is generator network, which generate a super-resolved image</span></span><br><span class="line">print(<span class="string">'# generator parameters:'</span>, <span class="built_in">sum</span>(<span class="built_in">param</span>.numel() <span class="keyword">for</span> <span class="built_in">param</span> <span class="keyword">in</span> netG.parameters()))</span><br><span class="line">netD = Discriminator()</span><br><span class="line"><span class="comment"># here is discriminator network, which decide whether the image is the real one or the super-resolved one</span></span><br><span class="line">print(<span class="string">'# discriminator parameters:'</span>, <span class="built_in">sum</span>(<span class="built_in">param</span>.numel() <span class="keyword">for</span> <span class="built_in">param</span> <span class="keyword">in</span> netD.parameters()))</span><br></pre></td></tr></table></figure>
<h2 id="关于pytorch的dataloader和dataset"><a href="#关于pytorch的dataloader和dataset" class="headerlink" title="关于pytorch的dataloader和dataset"></a>关于pytorch的dataloader和dataset</h2><p><a href="https://blog.csdn.net/qq_36556893/article/details/86505934" target="_blank" rel="noopener">参考网站</a></p>
<h2 id="自动求导"><a href="#自动求导" class="headerlink" title="自动求导"></a>自动求导</h2><p>只有浮点类型才可以对Tensor设置自动求导，如果是Int类型的话，会报如下错误：<img src="/2019/04/25/pytorch-learn/1.png" width="1">，所以一定要使用float进行自动求导。</p>
<h2 id="关于net-parameters"><a href="#关于net-parameters" class="headerlink" title="关于net.parameters()"></a>关于net.parameters()</h2><p>可以通过Module.parameters()获取网络的参数，也就是构建好神经网络后，网络的参数都保存在parameters()函数当中</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="title">print</span><span class="params">(net.parameters()</span></span>)</span><br><span class="line"></span><br><span class="line">para = list(net.parameters())</span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(para)</span></span></span><br><span class="line">#len返回列表项个数</span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(len(para)</span></span>)</span><br></pre></td></tr></table></figure>
<p>可以使用enumerate函数实现逐列表项输出列表元素和index，也就是：<br><figure class="highlight dart"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">num</span>,temp <span class="keyword">in</span> enumerate(para):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">'number:'</span>,<span class="built_in">num</span>)</span><br><span class="line">    <span class="built_in">print</span>(temp)</span><br></pre></td></tr></table></figure></p>
<h2 id="optimizer-step-和scheduler-step-的区别"><a href="#optimizer-step-和scheduler-step-的区别" class="headerlink" title="optimizer.step()和scheduler.step()的区别"></a>optimizer.step()和scheduler.step()的区别</h2><p>optimizer.step()通常用在每个mini-batch之中，而scheduler.step()通常用在epoch里面,但是不绝对，可以根据具体的需求来做。只有用了optimizer.step()，模型才会更新，而scheduler.step()是对lr进行调整。通常我们有<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">optimizer = optim.SGD(model.parameters(), lr = 0.01, momentum = 0.9)</span><br><span class="line">scheduler = lr_scheduler.StepLR(optimizer, step_size = 100, gamma = 0.1)</span><br><span class="line">model = net.train(model, loss_function, optimizer, scheduler, num_epochs = 100)</span><br></pre></td></tr></table></figure></p>
<p>在scheduler的step_size表示scheduler.step()每调用step_size次，对应的学习率就会按照策略调整一次。所以如果scheduler.step()是放在mini-batch里面，那么step_size指的是经过这么多次迭代，学习率改变一次。</p>
<h2 id="dataloader使用"><a href="#dataloader使用" class="headerlink" title="dataloader使用"></a>dataloader使用</h2><p>来源<a href="https://www.jianshu.com/p/8ea7fba72673" target="_blank" rel="noopener">简书</a></p>
<h3 id="加载头文件"><a href="#加载头文件" class="headerlink" title="加载头文件"></a>加载头文件</h3><figure class="highlight xl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from torch.utils.<span class="keyword">data</span> <span class="keyword">import</span> DataLoader, Sampler</span><br><span class="line">from torchvision <span class="keyword">import</span> datasets, transforms</span><br></pre></td></tr></table></figure>
<h3 id="transforms表示对图片的预处理方式"><a href="#transforms表示对图片的预处理方式" class="headerlink" title="transforms表示对图片的预处理方式"></a><strong>transforms</strong>表示对图片的预处理方式</h3><figure class="highlight roboconf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">data_transform=&#123;'<span class="attribute">train'</span>:transforms<span class="variable">.Compose</span>([</span><br><span class="line">                    # transforms<span class="variable">.RandomResizedCrop</span>(image_size),</span><br><span class="line">                    # transforms<span class="variable">.Resize</span>(224),</span><br><span class="line">                    transforms<span class="variable">.RandomResizedCrop</span>(int(image_size*1.2)),</span><br><span class="line">                    # transforms<span class="variable">.ToPILImage</span>(),</span><br><span class="line">                    transforms<span class="variable">.RandomAffine</span>(15),</span><br><span class="line">                    # transforms<span class="variable">.RandomHorizontalFlip</span>(),</span><br><span class="line">                    transforms<span class="variable">.RandomVerticalFlip</span>(),</span><br><span class="line">                    transforms<span class="variable">.RandomRotation</span>(10),</span><br><span class="line">                    transforms<span class="variable">.ColorJitter</span>(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),</span><br><span class="line">                    transforms<span class="variable">.RandomGrayscale</span>(),</span><br><span class="line">                    transforms<span class="variable">.TenCrop</span>(image_size),</span><br><span class="line">                    transforms<span class="variable">.Lambda</span>(lambda crops: torch<span class="variable">.stack</span>([transforms<span class="variable">.ToTensor</span>()(crop) for crop in crops])),</span><br><span class="line">                    transforms<span class="variable">.Lambda</span>(lambda crops: torch<span class="variable">.stack</span>([transforms<span class="variable">.Normalize</span>([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])(crop) for crop in crops])),</span><br><span class="line">                    # transforms<span class="variable">.FiveCop</span>(image_size),</span><br><span class="line">                    # Lambda(lambda crops: torch<span class="variable">.stack</span>([transfoms<span class="variable">.ToTensor</span>()(crop) for crop in crops])),</span><br><span class="line">                    # transforms<span class="variable">.ToTensor</span>(),</span><br><span class="line">                    # transforms<span class="variable">.Normalize</span>([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])</span><br><span class="line">                    ]),</span><br><span class="line">                "val":transforms<span class="variable">.Compose</span>([</span><br><span class="line">                    transforms<span class="variable">.Resize</span>(image_size),</span><br><span class="line">                    transforms<span class="variable">.CenterCrop</span>(image_size),</span><br><span class="line">                    transforms<span class="variable">.ToTensor</span>(),</span><br><span class="line">                    transforms<span class="variable">.Normalize</span>([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])</span><br><span class="line">                ]),</span><br><span class="line">                "test":transforms<span class="variable">.Compose</span>([</span><br><span class="line">                    transforms<span class="variable">.Resize</span>(image_size),</span><br><span class="line">                    transforms<span class="variable">.CenterCrop</span>(image_size),</span><br><span class="line">                    transforms<span class="variable">.ToTensor</span>(),</span><br><span class="line">                    transforms<span class="variable">.Normalize</span>([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])</span><br><span class="line">                ])&#125;</span><br></pre></td></tr></table></figure>
<h3 id="使用datasets-ImageFolder加载图片数据"><a href="#使用datasets-ImageFolder加载图片数据" class="headerlink" title="使用datasets.ImageFolder加载图片数据"></a>使用<strong>datasets.ImageFolder</strong>加载图片数据</h3><figure class="highlight sqf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">image_datasets=&#123;<span class="built_in">name</span>:datasets.ImageFolder(os.path.<span class="built_in">join</span>(rootpath,<span class="built_in">name</span>),data_transform[<span class="built_in">name</span>]) <span class="keyword">for</span> <span class="built_in">name</span> <span class="built_in">in</span> [<span class="string">'train'</span>,<span class="string">'val'</span>,<span class="string">'test'</span>]&#125;</span><br></pre></td></tr></table></figure>
<h3 id="生成dataloader"><a href="#生成dataloader" class="headerlink" title="生成dataloader"></a>生成<strong>dataloader</strong></h3><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dataloaders=&#123;name : torch<span class="selector-class">.utils</span><span class="selector-class">.data</span><span class="selector-class">.DataLoader</span>(image_datasets[name],batch_size=batch_size,shuffle=True) <span class="keyword">for</span> name <span class="keyword">in</span> [<span class="string">'train'</span>,<span class="string">'val'</span>]&#125;</span><br><span class="line">testDataloader=torch<span class="selector-class">.utils</span><span class="selector-class">.data</span><span class="selector-class">.DataLoader</span>(image_datasets[<span class="string">'test'</span>],batch_size=<span class="number">1</span>,shuffle=False)</span><br></pre></td></tr></table></figure>
<h3 id="每次读出一个batch-size的数据"><a href="#每次读出一个batch-size的数据" class="headerlink" title="每次读出一个batch_size的数据"></a>每次读出一个batch_size的数据</h3><figure class="highlight delphi"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> <span class="keyword">index</span>,item <span class="keyword">in</span> enumerate(dataloaders[<span class="string">'train'</span>])</span><br></pre></td></tr></table></figure>
<h2 id="设置梯度"><a href="#设置梯度" class="headerlink" title="设置梯度"></a>设置梯度</h2><p>深度学习很重要的一点是反向传播，所以梯度的计算尤为重要，pytorch中对于tensor可以自动的计算梯度，对于其中已经包含的层，梯度的计算也是自动的。但是当你使用一个fine-tunning的操作，或者自己定义层时，如何定义处理梯度问题，或者设置梯度就尤为关键了。这里介绍pytorch中如何开启或关闭tensor的梯度计算和层的梯度计算。</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x = torch.randn(5, 5)  # <span class="attribute">requires_grad</span>=<span class="literal">False</span> by default</span><br><span class="line">&gt;&gt;&gt; y = torch.randn(5, 5)  # <span class="attribute">requires_grad</span>=<span class="literal">False</span> by default</span><br><span class="line">&gt;&gt;&gt; z = torch.randn((5, 5), <span class="attribute">requires_grad</span>=<span class="literal">True</span>)</span><br><span class="line">&gt;&gt;&gt; a = x + y</span><br><span class="line">&gt;&gt;&gt; a.requires_grad</span><br><span class="line"><span class="literal">False</span></span><br><span class="line">&gt;&gt;&gt; b = a + z</span><br><span class="line">&gt;&gt;&gt; b.requires_grad</span><br><span class="line"><span class="literal">True</span></span><br></pre></td></tr></table></figure>
<p>pytorch的tensor生成函数randn中设置参数requires_grad能够开启或者关闭该tensor的梯度计算。从上面的结果可以看出梯度的计算是传递的，虽然a没有梯度，但是z有梯度，所以b也有了。</p>
<p>对于设置层的梯度计算，有下面的例子：<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载预训练的模型，这里是加载resnet18</span></span><br><span class="line">model = torchvision.models.resnet18(<span class="attribute">pretrained</span>=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> model.parameters():</span><br><span class="line">    param.requires_grad = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Replace the last fully-connected layer</span></span><br><span class="line"><span class="comment"># Parameters of newly constructed modules have requires_grad=True by default</span></span><br><span class="line">model.fc = nn.Linear(512, 100)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Optimize only the classifier</span></span><br><span class="line">optimizer = optim.SGD(model.fc.parameters(), <span class="attribute">lr</span>=1e-2, <span class="attribute">momentum</span>=0.9)</span><br></pre></td></tr></table></figure></p>
<p>这里主要是在<strong>fine-tunning</strong>的场合用的很多。首先使用torchvision加载一个预训练模型，resnet18，并且加载他的预训练参数。在fine-tunning的时候，我们不需要重新训练其上面的层的参数，因此我们设置其上的每一层的requires_grad为false。之后在其上增加一个fc层，会默认设置该层的requires_grad的为true。下面设置学习方法，SGD，并且只需要设置新增加的fc层的学习参数即可。</p>
<h2 id="保存和读取模型"><a href="#保存和读取模型" class="headerlink" title="保存和读取模型"></a>保存和读取模型</h2><figure class="highlight gams"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># Save <span class="keyword">and</span> load the entire <span class="keyword">model</span>.</span><br><span class="line">torch.save(resnet, <span class="string">'model.ckpt'</span>)</span><br><span class="line"><span class="keyword">model</span> = torch.load(<span class="string">'model.ckpt'</span>)</span><br><span class="line"></span><br><span class="line"># Save <span class="keyword">and</span> load only the <span class="keyword">model</span> <span class="keyword">parameters</span> (recommended).</span><br><span class="line">torch.save(resnet.state_dict(), <span class="string">'params.ckpt'</span>)</span><br><span class="line">resnet.load_state_dict(torch.load(<span class="string">'params.ckpt'</span>))</span><br></pre></td></tr></table></figure>
<h2 id="状态字典-state-dict"><a href="#状态字典-state-dict" class="headerlink" title="状态字典 state_dict"></a>状态字典 state_dict</h2><h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><p>state_dict 是一个简单的python的字典对象,将每一层与它的对应参数建立映射关系.(如model的每一层的weights及偏置等等)【只有那些参数可以训练的layer才会被保存到模型的state_dict中,如卷积层,线性层等等】。</p>
<p>优化器对象Optimizer也有一个state_dict,它包含了优化器的状态以及被使用的超参数(如lr, momentum,weight_decay等)</p>
<ul>
<li><p>state_dict是在定义了model或optimizer之后pytorch自动生成的,可以直接调用.常用的保存state_dict的格式是”.pt”或’.pth’的文件,即下面命令的 PATH=”./<em>*</em>.pt”。</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">torch</span><span class="selector-class">.save</span>(<span class="selector-tag">model</span><span class="selector-class">.state_dict</span>(), <span class="selector-tag">PATH</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>load_state_dict也是model或optimizer之后pytorch自动具备的函数,可以直接调用</p>
<figure class="highlight gams"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">model</span> = TheModelClass(*args, **kwargs)</span><br><span class="line"><span class="keyword">model</span>.load_state_dict(torch.load(PATH))</span><br><span class="line"><span class="keyword">model</span>.eval()</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>注意:model.eval() 的重要性,在2)中最后用到了model.eval(),是因为,只有在执行该命令后,”dropout层”及”batch normalization层”才会进入 evalution 模态. 而在”训练(training)模态”与”评估(evalution)模态”下,这两层有不同的表现形式.</p>
<h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3><ul>
<li><p>仅保存学习到的参数,用以下命令</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">torch</span><span class="selector-class">.save</span>(<span class="selector-tag">model</span><span class="selector-class">.state_dict</span>(), <span class="selector-tag">PATH</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>加载model.state_dict,用以下命令</p>
<figure class="highlight gams"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">model</span> = TheModelClass(*args, **kwargs)</span><br><span class="line"><span class="keyword">model</span>.load_state_dict(torch.load(PATH))</span><br><span class="line"><span class="keyword">model</span>.eval()</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>【备注】:model.load_state_dict的操作对象是<strong>一个具体的对象,而不能是文件名</strong></p>
<ul>
<li><p>保存整个model的状态,用以下命令</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">torch</span><span class="selector-class">.save</span>(<span class="selector-tag">model</span>,<span class="selector-tag">PATH</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>加载整个model的状态,用以下命令:</p>
<figure class="highlight gams"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># <span class="keyword">Model</span> class must be defined somewhere</span><br><span class="line"><span class="keyword">model</span> = torch.load(PATH)</span><br><span class="line"><span class="keyword">model</span>.eval()</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>state_dict 是一个python的字典格式,以字典的格式存储,然后以字典的格式被加载,而且<strong>只加载key匹配的项</strong></p>
<ul>
<li><p>仅加载某一层的训练的到的参数(某一层的state)</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">conv1_weight_state</span> = torch.load(<span class="string">'./model_state_dict.pt'</span>)[<span class="string">'conv1.weight'</span>]</span><br></pre></td></tr></table></figure>
</li>
<li><p>加载模型参数后,如何设置某层某参数的”是否需要训练”(param.requires_grad)</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> list(model<span class="selector-class">.pretrained</span><span class="selector-class">.parameters</span>()):</span><br><span class="line">    param<span class="selector-class">.requires_grad</span> = False</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>【注意】requires_grad的操作对象是tensor.</p>
<p>【疑问】能否直接对某个层直接之用requires_grad呢?例如:model.conv1.requires_grad=False</p>
<p>【回答】经测试,不可以.model.conv1 没有requires_grad属性</p>
<h2 id="model-train和model-eval"><a href="#model-train和model-eval" class="headerlink" title="model.train和model.eval"></a>model.train和model.eval</h2><p>上面在讲解读取model的时候提到需要说明model.eval()和model.train()，两条语句有固定的使用场景。</p>
<p>他俩的主要区别是：<br>model.train()启用BatchNormalization 和 Dropout；model.eval()不启用BatchNormalization 和 Dropout</p>
<h2 id="每一轮batch需要设置optimizer-zero-grad"><a href="#每一轮batch需要设置optimizer-zero-grad" class="headerlink" title="每一轮batch需要设置optimizer.zero_grad"></a>每一轮batch需要设置optimizer.zero_grad</h2><p>根据pytorch中的backward()函数的计算，当网络参量进行反馈时，梯度是被积累的而不是被替换掉；但是在每一个batch时毫无疑问并不需要将两个batch的梯度混合起来累积，因此这里就需要每个batch设置一遍zero_grad了</p>
<h2 id="detach"><a href="#detach" class="headerlink" title="detach"></a>detach</h2><p>来源于<a href="https://www.jianshu.com/p/f1bd4ff84926" target="_blank" rel="noopener">简书</a><br>detach所做的就是,重新声明一个变量,指向原变量的存放位置,但是requires_grad为false.更深入一点的理解是,计算图从detach过的变量这里就断了, 它变成了一个leaf_node.即使之后重新将它的requires_node置为true,它也不会具有梯度.</p>
<p>另一方面,在调用完backward函数之后,非leaf_node的梯度计算完会立刻被清空.这也是为什么在执行backward之前显存占用很大,执行完之后显存占用立刻下降很多的原因.当然,这其中也包含了一些中间结果被存在buffer中,调用结束后也会被释放.<br>至于另一个参数volatile,如果一个变量的volatile=true,它可以将所有依赖于它的节点全部设为volatile=true,优先级高于requires_grad=true.这样的节点不会进行求导,即使requires_grad为真,也无法进行反向传播.在inference中如果采用这种设置,可以实现一定程度的速度提升,并且节约大概一半显存.</p>
<h2 id="BatchNorm2d的参数解释"><a href="#BatchNorm2d的参数解释" class="headerlink" title="BatchNorm2d的参数解释"></a>BatchNorm2d的参数解释</h2><p>来源<a href="https://www.jianshu.com/p/a646cbc913b4" target="_blank" rel="noopener">简书</a>。</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.BatchNorm1d(num_features,</span><br><span class="line"><span class="attribute">eps</span>=1e-05,</span><br><span class="line"><span class="attribute">momentum</span>=0.1,</span><br><span class="line"><span class="attribute">affine</span>=<span class="literal">True</span>,</span><br><span class="line"><span class="attribute">track_running_stats</span>=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<h2 id="resnet实现"><a href="#resnet实现" class="headerlink" title="resnet实现"></a>resnet实现</h2><h3 id="ResNet模块"><a href="#ResNet模块" class="headerlink" title="ResNet模块"></a>ResNet模块</h3><p>来源<a href="https://blog.csdn.net/Dr_destiny/article/details/85253158" target="_blank" rel="noopener">CSDN</a></p>
<p>如下的左图对应于resnet-18/34使用的基本块，右图是50/101/152所使用的，由于他们都比较深，所以右图相比于左图使用了1x1卷积来降维。<br><img src="/2019/04/25/pytorch-learn/2.png" width="2"></p>
<ul>
<li><p>conv3x3:将原有的pytorch函数固定卷积和尺寸为3重新封装了一次</p>
</li>
<li><p>BasicBlock:搭建上图左边的模块</p>
</li>
</ul>
<blockquote>
<p>每个卷积块后面连接BN层进行归一化；</p>
<p>残差连接前的3x3卷积之后只接入BN，不使用ReLU，避免加和之后的特征皆为正，保持特征的多样；</p>
<p>跳层连接：两种情况，当模块输入和残差支路（3x3-&gt;3x3）的通道数一致时，直接相加；当两者通道不一致时（一般发生在分辨率降低之后，同分辨率一般通道数一致），需要对模块输入特征使用1x1卷积进行升/降维（步长为2，上面说了分辨率会降低），之后同样接BN，不用ReLU。</p>
</blockquote>
<ul>
<li>Bottleneck:搭建上图右边的模块</li>
</ul>
<blockquote>
<p>使用1x1卷积先降维，再使用3x3卷积进行特征提取，最后再使用1x1卷积把维度升回去；</p>
<p>每个卷积块后面连接BN层进行归一化；</p>
<p>残差连接前的1x1卷积之后只接入BN，不使用ReLU，避免加和之后的特征皆为正，保持特征的多样性。</p>
<p>跳层连接：两种情况，当模块输入和残差支路（1x1-&gt;3x3-&gt;1x1）的通道数一致时，直接相加；当两者通道不一致时（一般发生在分辨率降低之后，同分辨率一般通道数一致），需要对模块输入特征使用1x1卷积进行升/降维（步长为2，上面说了分辨率会降低），之后同样接BN，不用ReLU。</p>
</blockquote>
<h2 id="设置学习率衰减"><a href="#设置学习率衰减" class="headerlink" title="设置学习率衰减"></a>设置学习率衰减</h2><h3 id="使用案例"><a href="#使用案例" class="headerlink" title="使用案例"></a>使用案例</h3><p>对学习率（learning rate）进行衰减，下面的代码示范了如何每30个epoch按10%的速率衰减：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">adjust_learning_rate</span><span class="params">(optimizer, epoch)</span>:</span></span><br><span class="line">    <span class="string">"""Sets the learning rate to the initial LR decayed by 10 every 30 epochs"""</span></span><br><span class="line">    lr = args.lr * (<span class="number">0.1</span> ** (epoch // <span class="number">30</span>))</span><br><span class="line">    <span class="keyword">for</span> param_group <span class="keyword">in</span> optimizer.param_groups:</span><br><span class="line">        param_group[<span class="string">'lr'</span>] = lr</span><br></pre></td></tr></table></figure></p>
<h3 id="什么是param-groups"><a href="#什么是param-groups" class="headerlink" title="什么是param_groups?"></a>什么是param_groups?</h3><p>optimizer通过param_group来管理参数组.param_group中保存了参数组及其对应的学习率,动量等等.所以我们可以通过更改param_group[‘lr’]的值来更改对应参数组的学习率。Pytorch可以使用多个参数组，从而使网络的不通部分拥有不同的优化方式。(Pytorch不同的层使用不同的学习率参考：pytorch在不同的层使用不同的学习率)[<a href="https://blog.csdn.net/liuweiyuxiang/article/details/84647659" target="_blank" rel="noopener">https://blog.csdn.net/liuweiyuxiang/article/details/84647659</a>]</p>
<figure class="highlight stan"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 有两个`param_group`即,len(optim.param_groups)==2</span></span><br><span class="line"><span class="comment"># 没有指定学习率的group使用后后面lr参数指定的默认学习率。</span></span><br><span class="line">optim.SGD([</span><br><span class="line">                &#123;'params': <span class="title">model</span>.base.<span class="title">parameters</span>()&#125;,<span class="comment">#lr=lr=1e-2</span></span><br><span class="line">                &#123;'params': <span class="title">model</span>.classifier.<span class="title">parameters</span>(), 'lr': <span class="number">1e-3</span>&#125;</span><br><span class="line">            ], lr=<span class="number">1e-2</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment">#一个参数组</span></span><br><span class="line">optim.SGD(<span class="title">model</span>.<span class="title">parameters</span>(), lr=<span class="number">1e-2</span>, momentum=<span class="number">.9</span>)</span><br></pre></td></tr></table></figure>
<h2 id="inplace-True字段"><a href="#inplace-True字段" class="headerlink" title="inplace=True字段"></a>inplace=True字段</h2><p>在例如nn.ReLU(inplace=True)中的inplace字段是什么意思呢？有什么用？</p>
<p><strong>inplace=True的意思是进行原地操作，例如x=x+5，对x就是一个原地操作，y=x+5,x=y，完成了与x=x+5同样的功能但是不是原地操作，上面LeakyReLU中的inplace=True的含义是一样的，是对于Conv2d这样的上层网络传递下来的tensor直接进行修改，好处就是可以节省运算内存，不用多储存变量y</strong></p>
<h2 id="多标签分类与BCEloss"><a href="#多标签分类与BCEloss" class="headerlink" title="多标签分类与BCEloss"></a>多标签分类与BCEloss</h2><p>参考<a href="https://www.jianshu.com/p/ac3bec3dde3e" target="_blank" rel="noopener">简书</a> 和 <a href="https://blog.csdn.net/u010995990/article/details/79739887" target="_blank" rel="noopener">CSDN</a></p>

      
    </div>

    

    
    
    

    <div>
      
        
<div class="my_post_copyright">
  <script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script>
  
  <!-- JS库 sweetalert 可修改路径 -->
  <script src="https://cdn.bootcss.com/jquery/2.0.0/jquery.min.js"></script>
  <script src="https://unpkg.com/sweetalert/dist/sweetalert.min.js"></script>
  <p><span>本文标题:</span><a href="/2019/04/25/pytorch-learn/">pytorch的一些学习记录/困惑/笔记等(持续更新)</a></p>
  <p><span>文章作者:</span><a href="/" title="访问 Zeyuxiao 的个人博客">Zeyuxiao</a></p>
  <p><span>发布时间:</span>2019年04月25日 - 16:04</p>
  <p><span>最后更新:</span>2019年08月06日 - 16:08</p>
  <p><span>原始链接:</span><a href="/2019/04/25/pytorch-learn/" title="pytorch的一些学习记录/困惑/笔记等(持续更新)">https://zeyuxiao1997.github.io/2019/04/25/pytorch-learn/</a>
    <span class="copy-path" title="点击复制文章链接"><i class="fa fa-clipboard" data-clipboard-text="https://zeyuxiao1997.github.io/2019/04/25/pytorch-learn/" aria-label="复制成功！"></i></span>
  </p>
  <p><span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" title="Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)">署名-非商业性使用-禁止演绎 4.0 国际</a> 转载请保留原文链接及作者。</p>  
</div>
<script> 
    var clipboard = new Clipboard('.fa-clipboard');
    $(".fa-clipboard").click(function(){
      clipboard.on('success', function(){
        swal({   
          title: "",   
          text: '复制成功',
          icon: "success", 
          showConfirmButton: true
          });
    });
    });  
</script>

      
    </div>




    





    
      
    
    
      <div>
        <div id="reward-container">
  <div></div>
  <button id="reward-button" disable="enable" onclick="var qr = document.getElementById(&quot;qr&quot;); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    Donate
  </button>
  <div id="qr" style="display: none;">

    
      
      
        
      
      <div style="display: inline-block">
        <img src="/images/wec.png" alt="Zeyuxiao WeChat Pay">
        <p>WeChat Pay</p>
      </div>
    
      
      
        
      
      <div style="display: inline-block">
        <img src="/images/ali.png" alt="Zeyuxiao Alipay">
        <p>Alipay</p>
      </div>
    

  </div>
</div>

      </div>
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/pytorch/" rel="tag">  <i class="fa fa-tag"></i>  pytorch</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/04/22/paper-SRGAN/" rel="next" title="paper——Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network">
                <i class="fa fa-chevron-left"></i> paper——Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/04/28/camera/" rel="prev" title="IPS流程（camera成像原理的介绍）">
                IPS流程（camera成像原理的介绍） <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Zeyuxiao</p>
              <div class="site-description motion-element" itemprop="description"></div>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">43</span>
                    <span class="site-state-item-name">posts</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  
                    
                      <a href="/categories/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">11</span>
                    <span class="site-state-item-name">categories</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                      <a href="/tags/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">43</span>
                    <span class="site-state-item-name">tags</span>
                  </a>
                </div>
              
            </nav>
          

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://github.com/zeyuxiao1997" title="GitHub &rarr; https://github.com/zeyuxiao1997" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="mailto:zeyuxiao1997@gmail.com" title="E-Mail &rarr; mailto:zeyuxiao1997@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                </span>
              
            </div>
          

          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-inline">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-globe"></i>
                Links
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="http://en.ustc.edu.cn/" title="http://en.ustc.edu.cn/" rel="noopener" target="_blank">USTC official website</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="http://en.hfut.edu.cn/index.php" title="http://en.hfut.edu.cn/index.php" rel="noopener" target="_blank">HFUT official website</a>
                  </li>
                
              </ul>
            </div>
          

          
            
          
          

        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#查看网络参数总量"><span class="nav-number">1.</span> <span class="nav-text">查看网络参数总量</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#关于pytorch的dataloader和dataset"><span class="nav-number">2.</span> <span class="nav-text">关于pytorch的dataloader和dataset</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#自动求导"><span class="nav-number">3.</span> <span class="nav-text">自动求导</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#关于net-parameters"><span class="nav-number">4.</span> <span class="nav-text">关于net.parameters()</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#optimizer-step-和scheduler-step-的区别"><span class="nav-number">5.</span> <span class="nav-text">optimizer.step()和scheduler.step()的区别</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#dataloader使用"><span class="nav-number">6.</span> <span class="nav-text">dataloader使用</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#加载头文件"><span class="nav-number">6.1.</span> <span class="nav-text">加载头文件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#transforms表示对图片的预处理方式"><span class="nav-number">6.2.</span> <span class="nav-text">transforms表示对图片的预处理方式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#使用datasets-ImageFolder加载图片数据"><span class="nav-number">6.3.</span> <span class="nav-text">使用datasets.ImageFolder加载图片数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#生成dataloader"><span class="nav-number">6.4.</span> <span class="nav-text">生成dataloader</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#每次读出一个batch-size的数据"><span class="nav-number">6.5.</span> <span class="nav-text">每次读出一个batch_size的数据</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#设置梯度"><span class="nav-number">7.</span> <span class="nav-text">设置梯度</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#保存和读取模型"><span class="nav-number">8.</span> <span class="nav-text">保存和读取模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#状态字典-state-dict"><span class="nav-number">9.</span> <span class="nav-text">状态字典 state_dict</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#概念"><span class="nav-number">9.1.</span> <span class="nav-text">概念</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#使用"><span class="nav-number">9.2.</span> <span class="nav-text">使用</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#model-train和model-eval"><span class="nav-number">10.</span> <span class="nav-text">model.train和model.eval</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#每一轮batch需要设置optimizer-zero-grad"><span class="nav-number">11.</span> <span class="nav-text">每一轮batch需要设置optimizer.zero_grad</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#detach"><span class="nav-number">12.</span> <span class="nav-text">detach</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#BatchNorm2d的参数解释"><span class="nav-number">13.</span> <span class="nav-text">BatchNorm2d的参数解释</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#resnet实现"><span class="nav-number">14.</span> <span class="nav-text">resnet实现</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#ResNet模块"><span class="nav-number">14.1.</span> <span class="nav-text">ResNet模块</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#设置学习率衰减"><span class="nav-number">15.</span> <span class="nav-text">设置学习率衰减</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#使用案例"><span class="nav-number">15.1.</span> <span class="nav-text">使用案例</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#什么是param-groups"><span class="nav-number">15.2.</span> <span class="nav-text">什么是param_groups?</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#inplace-True字段"><span class="nav-number">16.</span> <span class="nav-text">inplace=True字段</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#多标签分类与BCEloss"><span class="nav-number">17.</span> <span class="nav-text">多标签分类与BCEloss</span></a></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

      

    </div>
  </aside>
  


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zeyuxiao</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
    <span title="Symbols count total">52k</span>
  

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    
    <span title="Reading time total">1:05</span>
  
</div>


  <div class="powered-by">Powered by <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> v3.8.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> v7.1.0</div>




        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="post-meta-item-icon">
      <i class="fa fa-user"></i>
    </span>
    <span class="site-uv" title="Total Visitors">
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
    </span>
  

  
    <span class="post-meta-divider">|</span>
  

  
    <span class="post-meta-item-icon">
      <i class="fa fa-eye"></i>
    </span>
    <span class="site-pv" title="Total Views">
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
    </span>
  
</div>









        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/utils.js?v=7.1.0"></script>

  <script src="/js/motion.js?v=7.1.0"></script>



  
  


  <script src="/js/schemes/muse.js?v=7.1.0"></script>




  
  <script src="/js/scrollspy.js?v=7.1.0"></script>
<script src="/js/post-details.js?v=7.1.0"></script>



  


  <script src="/js/next-boot.js?v=7.1.0"></script>


  

  

  

  


  


  




  
  
  <script>
    
    function addCount(Counter) {
      var $visitors = $('.leancloud_visitors');
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();

      Counter('get', '/classes/Counter', { where: JSON.stringify({ url }) })
        .done(function({ results }) {
          if (results.length > 0) {
            var counter = results[0];
            
            Counter('put', '/classes/Counter/' + counter.objectId, JSON.stringify({ time: { '__op': 'Increment', 'amount': 1 } }))
            
              .done(function() {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.time + 1);
              })
            
              .fail(function ({ responseJSON }) {
                console.log('Failed to save Visitor num, with error message: ' + responseJSON.error);
              })
          } else {
            
              Counter('post', '/classes/Counter', JSON.stringify({ title: title, url: url, time: 1 }))
                .done(function() {
                  var $element = $(document.getElementById(url));
                  $element.find('.leancloud-visitors-count').text(1);
                })
                .fail(function() {
                  console.log('Failed to create');
                });
            
          }
        })
        .fail(function ({ responseJSON }) {
          console.log('LeanCloud Counter Error: ' + responseJSON.code + ' ' + responseJSON.error);
        });
    }
    

    $(function() {
      $.get('https://app-router.leancloud.cn/2/route?appId=' + 'yg4XxdtX7BdTnUd6TVev9bVe-gzGzoHsz')
        .done(function({ api_server }) {
          var Counter = function(method, url, data) {
            return $.ajax({
              method: method,
              url: 'https://' + api_server + '/1.1' + url,
              headers: {
                'X-LC-Id': 'yg4XxdtX7BdTnUd6TVev9bVe-gzGzoHsz',
                'X-LC-Key': 'KxH8toeOBo0RHkyVGcbo8Y2l',
                'Content-Type': 'application/json',
              },
              data: data
            });
          };
          
            addCount(Counter);
          
        });
    });
  </script>



  

  
  

  
  

  


  

  

  

  

  

  

  

  

  

  

  

</body>
</html>
